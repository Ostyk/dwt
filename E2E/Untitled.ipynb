{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import skimage\n",
    "import skimage.io\n",
    "import scipy.io as sio\n",
    "import skimage.transform\n",
    "import sys\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "VGG_MEAN = [103.939, 116.779, 123.68]\n",
    "\n",
    "def read_mat(path):\n",
    "    return np.load(path)\n",
    "\n",
    "def write_mat(path, m):\n",
    "    np.save(path, m)\n",
    "\n",
    "def read_ids(path):\n",
    "    return [line.rstrip('\\n') for line in open(path)]\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import json\n",
    "from collections import namedtuple\n",
    "from tqdm import tqdm\n",
    "#from train_direction import initialize_model\n",
    "from model_io import *\n",
    "import sys\n",
    "from loss_function import *\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  train  val\n"
     ]
    }
   ],
   "source": [
    "!ls ../../pytorch-nested-unet/outputs/42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch_Feeder:\n",
    "    def __init__(self, dataset_path, unet_output_path, subset, batchSize, padWidth=None, padHeight=None, flip=False, keepEmpty=True, train=True, img_shape=(384,384)):\n",
    "        \n",
    "        assert subset in ['train', 'val', 'test'], \"wrong name of subset\"\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "        self._dataset_path = dataset_path\n",
    "        self._subset = subset\n",
    "        self._train = train\n",
    "        self._batchSize = batchSize\n",
    "        self._padWidth = padWidth\n",
    "        self._padHeight = padHeight\n",
    "        self._flip = flip\n",
    "        self._keepEmpty = keepEmpty\n",
    "        self.img_shape = img_shape\n",
    "        \n",
    "        self.unet_output_path = os.path.join(unet_output_path, subset)\n",
    "    \n",
    "        mask_path = os.path.join(self._dataset_path, 'polygons.json')\n",
    "        with open(mask_path) as f:\n",
    "            self.polygons = json.load(f)\n",
    "        \n",
    "        # TO DO: implement shuffling\n",
    "        # TO DO: support batch wise inference\n",
    "        \n",
    "\n",
    "    def set_paths(self):\n",
    "        self.root = os.path.join(self._dataset_path, self._subset)\n",
    "        print('scanning {}'.format(self.root))\n",
    "        self._paths = []\n",
    "        \n",
    "        imgs = sorted([i for i in os.listdir(self.root) if i.endswith('.png')])\n",
    "        gt_DT = sorted([i for i in os.listdir(self.root) if i.endswith('.npy') and 'DT' in i])\n",
    "        gt_angle = sorted([i for i in os.listdir(self.root) if i.endswith('.npy') and 'angle' in i])\n",
    "        unet_outputs = sorted([i for i in os.listdir(self.unet_output_path) if i.endswith('.png')]) #actually nested unet++\n",
    "        \n",
    "        assert len(imgs)==len(unet_outputs), 'mismatch in imgs and unet++ outputs'\n",
    "#         if self._train:\n",
    "\n",
    "        # TO DO: support batch wise inference\n",
    "\n",
    "        entry = namedtuple(\"gt\", \"index img angle dt unet\")\n",
    "        for index, (img, angle, dt, unet) in enumerate(zip(imgs, gt_angle, gt_DT, unet_outputs)):\n",
    "            self._paths.append(entry(index, img, angle, dt, unet))\n",
    "\n",
    "             \n",
    "\n",
    "            self.shuffle()\n",
    "#         else:\n",
    "#             for id in idList:\n",
    "#                 self._paths.append([id, imageDir + '/' + id + '_leftImg8bit.png',\n",
    "#                                     ssDir + '/' + id + '_unified_ss.mat'])\n",
    "\n",
    "        self._numData = len(self._paths)\n",
    "\n",
    "        if self._numData < self._batchSize:\n",
    "            self._batchSize = self._numData\n",
    "\n",
    "    def shuffle(self):\n",
    "        np.random.shuffle(self._paths)\n",
    "\n",
    "    def next_batch(self):\n",
    "        idBatch = []\n",
    "        \n",
    "        dirBatch = []\n",
    "        \n",
    "        imageBatch = np.zeros((self._batchSize, self.img_shape[0], self.img_shape[1], 3), dtype=np.int32)\n",
    "        gtBatch = np.zeros((self._batchSize,  self.img_shape[0], self.img_shape[1]), dtype=np.float32)\n",
    "        ssBatch = np.zeros((self._batchSize,  self.img_shape[0], self.img_shape[1]))\n",
    "\n",
    "        tmp = 0\n",
    "        \n",
    "        if self._train:\n",
    "            while(len(idBatch) < self._batchSize):\n",
    "                \n",
    "                current_tuple = self._paths[self._index_in_epoch]\n",
    "                \n",
    "                rgb = self.load_rgb(os.path.join(self.root, current_tuple.img))\n",
    "        \n",
    "                #angle = self.load_npy(os.path.join(self.root, current_tuple.angle))\n",
    "                dt = self.load_npy(os.path.join(self.root, current_tuple.dt))\n",
    "\n",
    "                mask = self.load_rgb(os.path.join(self.root, current_tuple.unet))\n",
    "                imageBatch[tmp] = rgb\n",
    "                gtBatch[tmp] = dt\n",
    "                ssBatch[tmp] = mask\n",
    "\n",
    "                idBatch.append(current_tuple.index)\n",
    "                \n",
    "                tmp+=1\n",
    "                if tmp==self._batchSize-1:\n",
    "                    tmp=0\n",
    "                self._index_in_epoch += 1\n",
    "                \n",
    "                if self._index_in_epoch == self._numData:\n",
    "                    self._index_in_epoch = 0\n",
    "                    self.shuffle()\n",
    "\n",
    "            if self._flip and np.random.uniform() > 0.5:\n",
    "                for i in range(len(imageBatch)):\n",
    "                    for j in range(3):\n",
    "                        imageBatch[i,:,:,j] = np.fliplr(imageBatch[i,:,:,j])\n",
    "\n",
    "                    weightBatch[i] = np.fliplr(weightBatch[i])\n",
    "                    ssBatch[i] = np.fliplr(ssBatch[i])\n",
    "                    ssMaskBatch[i] = np.fliplr(ssMaskBatch[i])\n",
    "\n",
    "                    for j in range(2):\n",
    "                        gtBatch[i,:,:,j] = np.fliplr(gtBatch[i,:,:,j])\n",
    "\n",
    "                    gtBatch[i,:,:,0] = -1 * gtBatch[i,:,:,0]\n",
    "            return dirBatch, gtBatch, ssBatch\n",
    "        else:\n",
    "            pass\n",
    "            self._index_in_epoch += self._batchSize\n",
    "            return imageBatch, ssBatch\n",
    "        \n",
    "    def total_samples(self):\n",
    "        return self._numData\n",
    "\n",
    "    def image_scaling(self, rgb_in):\n",
    "        if rgb_in.dtype == np.float32:\n",
    "            rgb_in = rgb_in*255\n",
    "        elif rgb_in.dtype == np.uint8:\n",
    "            rgb_in = rgb_in.astype(np.float32)\n",
    "\n",
    "        # VGG16 was trained using opencv which reads images as BGR, but skimage reads images as RGB\n",
    "        rgb_out = np.zeros(rgb_in.shape).astype(np.float32)\n",
    "        rgb_out[:,:,0] = rgb_in[:,:,2] - VGG_MEAN[2]\n",
    "        rgb_out[:,:,1] = rgb_in[:,:,1] - VGG_MEAN[1]\n",
    "        rgb_out[:,:,2] = rgb_in[:,:,0] - VGG_MEAN[0]\n",
    "\n",
    "        return rgb_out\n",
    "\n",
    "    def pad(self, data):\n",
    "        if self._padHeight and self._padWidth:\n",
    "            if data.ndim == 3:\n",
    "                npad = ((0,self._padHeight-data.shape[0]),(0,self._padWidth-data.shape[1]),(0,0))\n",
    "            elif data.ndim == 2:\n",
    "                npad = ((0, self._padHeight - data.shape[0]), (0, self._padWidth - data.shape[1]))\n",
    "            padData = np.pad(data, npad, mode='constant', constant_values=0)\n",
    "\n",
    "        else:\n",
    "            padData = data\n",
    "\n",
    "        return padData\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_rgb(path):\n",
    "        return cv2.cvtColor(cv2.imread(path), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_mask(img, polygons):\n",
    "        \"\"\"\n",
    "        Transforms polygons of a single image into a 2D binary numpy array\n",
    "        \n",
    "        :param img: just to get the corresponding shape of the output array\n",
    "        :param polygons: - dict\n",
    "        \n",
    "        :return mask: numpy array with drawn over and touching polygons\n",
    "        \"\"\"\n",
    "        mask = np.zeros([img.shape[0], img.shape[1]], dtype=np.uint8)\n",
    "        for curr_pol in polygons:\n",
    "            cv2.fillPoly(mask, [np.array(curr_pol, 'int32')], 255)\n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_npy(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            depth = np.load(f)\n",
    "        return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanning ../../watershednet/data/for_training/42/train\n",
      "scanning ../../watershednet/data/for_training/42/val\n"
     ]
    }
   ],
   "source": [
    "trainFeeder = Batch_Feeder(dataset_path=\"../../watershednet/data/for_training/42/\", \n",
    "                           unet_output_path = '../../pytorch-nested-unet/outputs/42',\n",
    "                           subset='train',\n",
    "                           batchSize=batchSize,\n",
    "                           padWidth=None,\n",
    "                           padHeight=None, \n",
    "                           flip=False,\n",
    "                           keepEmpty=False,\n",
    "                           train=True,\n",
    "                           img_shape = (384,384))\n",
    "trainFeeder.set_paths()\n",
    "\n",
    "valFeeder = Batch_Feeder(dataset_path=\"../../watershednet/data/for_training/42/\", \n",
    "                         unet_output_path = '../../pytorch-nested-unet/outputs/42',\n",
    "                           subset='val',\n",
    "                           batchSize=batchSize,\n",
    "                           padWidth=None,\n",
    "                           padHeight=None, \n",
    "                           flip=False,\n",
    "                           keepEmpty=False,\n",
    "                           train=True,\n",
    "                           img_shape = (384,384))\n",
    "valFeeder.set_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network_init import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputChannels = 16\n",
    "savePrefix = \"\"\n",
    "outputPrefix = \"\"\n",
    "# 0=car, 1=person, 2=rider, 3=motorcycle, 4=bicycle, 5=truck, 6=bus, 7=train\n",
    "train = True\n",
    "batchSize = 3\n",
    "learningRate = 5e-6 # usually i use 5e-6\n",
    "wd = 1e-6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"../best_models\"\n",
    "modelWeightPaths = [os.path.join(model_dir, i) for i in os.listdir(model_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../best_models/direction_unified_CR_unified_CR_pretrain_150.mat',\n",
       " '../best_models/depth_unified_CR_CR_pretrain_300.mat']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelWeightPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(wd=wd, modelWeightPaths=modelWeightPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputChannels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempting to build model\n",
      "building direction net\n",
      "WARNING:tensorflow:From /home/michalnarbutt/dwt/E2E/e2e_model.py:120: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/michalnarbutt/dwt/E2E/e2e_model.py:167: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "loaded direction/conv1_1/weights\n",
      "WARNING:tensorflow:From /home/michalnarbutt/dwt/E2E/e2e_model.py:179: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/michalnarbutt/dwt/E2E/e2e_model.py:181: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/michalnarbutt/dwt/E2E/e2e_model.py:184: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "loaded direction/conv1_1/biases\n",
      "loaded direction/conv1_2/weights\n",
      "loaded direction/conv1_2/biases\n",
      "WARNING:tensorflow:From /home/michalnarbutt/dwt/E2E/e2e_model.py:112: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "loaded direction/conv2_1/weights\n",
      "loaded direction/conv2_1/biases\n",
      "loaded direction/conv2_2/weights\n",
      "loaded direction/conv2_2/biases\n",
      "loaded direction/conv3_1/weights\n",
      "loaded direction/conv3_1/biases\n",
      "loaded direction/conv3_2/weights\n",
      "loaded direction/conv3_2/biases\n",
      "loaded direction/conv3_3/weights\n",
      "loaded direction/conv3_3/biases\n",
      "WARNING:tensorflow:From /home/michalnarbutt/dwt/E2E/e2e_model.py:116: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "loaded direction/conv4_1/weights\n",
      "loaded direction/conv4_1/biases\n",
      "loaded direction/conv4_2/weights\n",
      "loaded direction/conv4_2/biases\n",
      "loaded direction/conv4_3/weights\n",
      "loaded direction/conv4_3/biases\n",
      "loaded direction/conv5_1/weights\n",
      "loaded direction/conv5_1/biases\n",
      "loaded direction/conv5_2/weights\n",
      "loaded direction/conv5_2/biases\n",
      "loaded direction/conv5_3/weights\n",
      "loaded direction/conv5_3/biases\n",
      "loaded direction/fcn5_1/weights\n",
      "loaded direction/fcn5_1/biases\n",
      "loaded direction/fcn5_2/weights\n",
      "loaded direction/fcn5_2/biases\n",
      "loaded direction/fcn5_3/weights\n",
      "loaded direction/fcn5_3/biases\n",
      "loaded direction/fcn4_1/weights\n",
      "loaded direction/fcn4_1/biases\n",
      "loaded direction/fcn4_2/weights\n",
      "loaded direction/fcn4_2/biases\n",
      "loaded direction/fcn4_3/weights\n",
      "loaded direction/fcn4_3/biases\n",
      "loaded direction/fcn3_1/weights\n",
      "loaded direction/fcn3_1/biases\n",
      "loaded direction/fcn3_2/weights\n",
      "loaded direction/fcn3_2/biases\n",
      "loaded direction/fcn3_3/weights\n",
      "loaded direction/fcn3_3/biases\n",
      "loaded direction/upscore5_3/up_filter\n",
      "loaded direction/upscore4_3/up_filter\n",
      "loaded direction/fuse_1/weights\n",
      "loaded direction/fuse_1/biases\n",
      "loaded direction/fuse_2/weights\n",
      "loaded direction/fuse_2/biases\n",
      "loaded direction/fuse_3/weights\n",
      "loaded direction/fuse_3/biases\n",
      "loaded direction/upscore3_1/up_filter\n",
      "built the direction net!\n",
      "building depth net\n",
      "loaded depth/conv1_1/weights\n",
      "loaded depth/conv1_1/biases\n",
      "loaded depth/conv1_2/weights\n",
      "loaded depth/conv1_2/biases\n",
      "loaded depth/conv2_1/weights\n",
      "loaded depth/conv2_1/biases\n",
      "loaded depth/conv2_2/weights\n",
      "loaded depth/conv2_2/biases\n",
      "loaded depth/conv2_3/weights\n",
      "loaded depth/conv2_3/biases\n",
      "loaded depth/conv2_4/weights\n",
      "loaded depth/conv2_4/biases\n",
      "loaded depth/fcn1/weights\n",
      "loaded depth/fcn1/biases\n",
      "WARNING:tensorflow:From /home/michalnarbutt/dwt/E2E/e2e_model.py:138: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "loaded depth/fcn2/weights\n",
      "loaded depth/fcn2/biases\n",
      "loaded depth/upscore/up_filter\n",
      "WARNING:tensorflow:From /home/michalnarbutt/dwt/E2E/e2e_model.py:105: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "built the depth net!\n",
      "built the model\n",
      "WARNING:tensorflow:From /home/michalnarbutt/dwt/E2E/loss_function.py:8: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/michalnarbutt/dwt/E2E/loss_function.py:10: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/michalnarbutt/dwt/E2E/loss_function.py:16: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/michalnarbutt/dwt/E2E/loss_function.py:45: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "setting adam optimizer\n",
      "WARNING:tensorflow:From /home/michalnarbutt/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/michalnarbutt/.local/lib/python3.7/site-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "attempting to run init\n",
      "completed init\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'initialIteration' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ab63e3b3a45b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'initialIteration' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tfBatchImages = tf.placeholder(\"float\", shape=[None, 384, 384, 3])\n",
    "    tfBatchGT = tf.placeholder(\"float\", shape=[None, 384, 384])\n",
    "    tfBatchSS = tf.placeholder(\"float\", shape=[None, 384, 384])\n",
    "    keepProb = tf.placeholder(\"float\")\n",
    "\n",
    "    with tf.name_scope(\"model_builder\"):\n",
    "        print (\"attempting to build model\")\n",
    "        model.build(tfBatchImages, tfBatchSS, keepProb=keepProb)\n",
    "        print (\"built the model\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    \n",
    "    loss = modelTotalLoss(pred=model.outputData, gt=tfBatchGT, ss=tfBatchSS, outputChannels=outputChannels)\n",
    "    numPredicted = countTotal(ss=tfBatchSS)\n",
    "    numCorrect = countCorrect(pred=model.outputData, gt=tfBatchGT, ss=tfBatchSS, k=1, outputChannels=outputChannels)\n",
    "\n",
    "    print (\"setting adam optimizer\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learningRate).minimize(loss=loss)\n",
    "\n",
    "    init = tf.initialize_all_variables()\n",
    "    print (\"attempting to run init\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    sess.run(init)\n",
    "    print (\"completed init\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    iteration = initialIteration\n",
    "\n",
    "    while iteration < 1000:\n",
    "        batchLosses = []\n",
    "        totalPredicted = 0\n",
    "        totalCorrect = 0\n",
    "\n",
    "        for k in range(int(math.floor(valFeeder.total_samples() / batchSize))):\n",
    "            imageBatch, gtBatch, ssBatch = valFeeder.next_batch()\n",
    "\n",
    "            batchLoss, batchPredicted, batchCorrect = sess.run(\n",
    "                [loss, numPredicted, numCorrect],\n",
    "                feed_dict={tfBatchImages: imageBatch,\n",
    "                           tfBatchGT: gtBatch,\n",
    "                           tfBatchSS: ssBatch,\n",
    "                           keepProb: 1.0})\n",
    "\n",
    "            batchLosses.append(batchLoss)\n",
    "            totalPredicted += batchPredicted\n",
    "            totalCorrect += batchCorrect\n",
    "\n",
    "        if np.isnan(np.mean(batchLosses)):\n",
    "            print (\"LOSS RETURNED NaN\")\n",
    "            sys.stdout.flush()\n",
    "            print(1) #change to return\n",
    "\n",
    "        print (\"%s Itr: %d - val loss: %.6f, correct: %.6f\" % (time.strftime(\"%H:%M:%S\"),\n",
    "        iteration, float(np.mean(batchLosses)), totalCorrect / totalPredicted))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        if (iteration > 0 and iteration % 5 == 0) or checkSaveFlag(modelSavePath):\n",
    "            modelSaver(sess, modelSavePath, savePrefix, iteration)\n",
    "\n",
    "        #for j in range(10):\n",
    "        for j in range(int(math.floor(trainFeeder.total_samples() / batchSize))):\n",
    "            # print (\"attempting to run train batch\"\n",
    "            # sys.stdout.flush()\n",
    "\n",
    "            imageBatch, gtBatch, ssBatch = trainFeeder.next_batch()\n",
    "            sess.run(train_op, feed_dict={tfBatchImages: imageBatch,\n",
    "                                          tfBatchGT: gtBatch,\n",
    "                                          tfBatchSS: ssBatch,\n",
    "                                          keepProb: 0.7})\n",
    "            # print (\"ran one iteration\"\n",
    "\n",
    "        iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, outputChannels, learningRate, trainFeeder, valFeeder,\n",
    "                modelSavePath=None, savePrefix=None, initialIteration=1, batchSize=1):\n",
    "    with tf.Session() as sess:\n",
    "        tfBatchImages = tf.placeholder(\"float\", shape=[None, 384, 384, 3])\n",
    "        tfBatchGT = tf.placeholder(\"float\", shape=[None, 384, 384])\n",
    "        tfBatchSS = tf.placeholder(\"float\", shape=[None, 384, 384])\n",
    "        keepProb = tf.placeholder(\"float\")\n",
    "\n",
    "        with tf.name_scope(\"model_builder\"):\n",
    "            print (\"attempting to build model\")\n",
    "            model.build(tfBatchImages, tfBatchSS, tfBatchSSMask, keepProb=keepProb)\n",
    "            print (\"built the model\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        loss = modelTotalLoss(pred=model.outputData, gt=tfBatchGT, weight=tfBatchWeight, ss=tfBatchSS, outputChannels=outputChannels)\n",
    "        numPredictedWeighted = countTotalWeighted(ss=tfBatchSS, weight=tfBatchWeight)\n",
    "        numPredicted = countTotal(ss=tfBatchSS)\n",
    "        numCorrect = countCorrect(pred=model.outputData, gt=tfBatchGT, ss=tfBatchSS, k=1, outputChannels=outputChannels)\n",
    "\n",
    "        print (\"setting adam optimizer\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate=learningRate).minimize(loss=loss)\n",
    "\n",
    "        init = tf.initialize_all_variables()\n",
    "        print (\"attempting to run init\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        sess.run(init)\n",
    "        print (\"completed init\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        iteration = initialIteration\n",
    "\n",
    "        while iteration < 1000:\n",
    "            batchLosses = []\n",
    "            totalPredictedWeighted = 0\n",
    "            totalPredicted = 0\n",
    "            totalCorrect = 0\n",
    "\n",
    "            for k in range(int(math.floor(valFeeder.total_samples() / batchSize))):\n",
    "                imageBatch, gtBatch, weightBatch, ssBatch, ssMaskBatch, _ = valFeeder.next_batch()\n",
    "\n",
    "                batchLoss, batchPredicted, batchPredictedWeighted, batchCorrect = sess.run(\n",
    "                    [loss, numPredicted, numPredictedWeighted, numCorrect],\n",
    "                    feed_dict={tfBatchImages: imageBatch,\n",
    "                               tfBatchGT: gtBatch,\n",
    "                               tfBatchWeight: weightBatch,\n",
    "                               tfBatchSS: ssBatch,\n",
    "                               tfBatchSSMask: ssMaskBatch,\n",
    "                               keepProb: 1.0})\n",
    "\n",
    "                batchLosses.append(batchLoss)\n",
    "                totalPredicted += batchPredicted\n",
    "                totalPredictedWeighted += batchPredictedWeighted\n",
    "                totalCorrect += batchCorrect\n",
    "\n",
    "            if np.isnan(np.mean(batchLosses)):\n",
    "                print (\"LOSS RETURNED NaN\")\n",
    "                sys.stdout.flush()\n",
    "                return 1\n",
    "\n",
    "            print (\"%s Itr: %d - val loss: %.6f, correct: %.6f\" % (time.strftime(\"%H:%M:%S\"),\n",
    "            iteration, float(np.mean(batchLosses)), totalCorrect / totalPredicted)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            if (iteration > 0 and iteration % 5 == 0) or checkSaveFlag(modelSavePath):\n",
    "                modelSaver(sess, modelSavePath, savePrefix, iteration)\n",
    "\n",
    "            #for j in range(10):\n",
    "            for j in range(int(math.floor(trainFeeder.total_samples() / batchSize))):\n",
    "                # print (\"attempting to run train batch\"\n",
    "                # sys.stdout.flush()\n",
    "\n",
    "                imageBatch, gtBatch, weightBatch, ssBatch, ssMaskBatch, _ = trainFeeder.next_batch()\n",
    "                sess.run(train_op, feed_dict={tfBatchImages: imageBatch,\n",
    "                                              tfBatchGT: gtBatch,\n",
    "                                              tfBatchWeight: weightBatch,\n",
    "                                              tfBatchSS: ssBatch,\n",
    "                                              tfBatchSSMask: ssMaskBatch,\n",
    "                                              keepProb: 0.7})\n",
    "                # print (\"ran one iteration\"\n",
    "\n",
    "            iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_model(model, outputChannels, learningRate, trainFeeder, valFeeder,\n",
    "                modelSavePath=None, savePrefix=None, initialIteration=1, batchSize=1):\n",
    "    with tf.Session() as sess:\n",
    "        tfBatchImages = tf.placeholder(\"float\")\n",
    "        tfBatchGT = tf.placeholder(\"float\")\n",
    "        tfBatchWeight = tf.placeholder(\"float\")\n",
    "        tfBatchSS = tf.placeholder(\"float\")\n",
    "        tfBatchSSMask = tf.placeholder(\"float\")\n",
    "        keepProb = tf.placeholder(\"float\")\n",
    "\n",
    "        with tf.name_scope(\"model_builder\"):\n",
    "            print \"attempting to build model\"\n",
    "            model.build(tfBatchImages, tfBatchSS, tfBatchSSMask, keepProb=keepProb)\n",
    "            print \"built the model\"\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        loss = modelTotalLoss(pred=model.outputData, gt=tfBatchGT, weight=tfBatchWeight, ss=tfBatchSS, outputChannels=outputChannels)\n",
    "        numPredictedWeighted = countTotalWeighted(ss=tfBatchSS, weight=tfBatchWeight)\n",
    "        numPredicted = countTotal(ss=tfBatchSS)\n",
    "        numCorrect = countCorrect(pred=model.outputData, gt=tfBatchGT, ss=tfBatchSS, k=1, outputChannels=outputChannels)\n",
    "\n",
    "        print \"setting adam optimizer\"\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate=learningRate).minimize(loss=loss)\n",
    "\n",
    "        init = tf.initialize_all_variables()\n",
    "        print \"attempting to run init\"\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        sess.run(init)\n",
    "        print \"completed init\"\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        iteration = initialIteration\n",
    "\n",
    "        while iteration < 1000:\n",
    "            batchLosses = []\n",
    "            totalPredictedWeighted = 0\n",
    "            totalPredicted = 0\n",
    "            totalCorrect = 0\n",
    "\n",
    "            for k in range(int(math.floor(valFeeder.total_samples() / batchSize))):\n",
    "                imageBatch, gtBatch, weightBatch, ssBatch, ssMaskBatch, _ = valFeeder.next_batch()\n",
    "\n",
    "                batchLoss, batchPredicted, batchPredictedWeighted, batchCorrect = sess.run(\n",
    "                    [loss, numPredicted, numPredictedWeighted, numCorrect],\n",
    "                    feed_dict={tfBatchImages: imageBatch,\n",
    "                               tfBatchGT: gtBatch,\n",
    "                               tfBatchWeight: weightBatch,\n",
    "                               tfBatchSS: ssBatch,\n",
    "                               tfBatchSSMask: ssMaskBatch,\n",
    "                               keepProb: 1.0})\n",
    "\n",
    "                batchLosses.append(batchLoss)\n",
    "                totalPredicted += batchPredicted\n",
    "                totalPredictedWeighted += batchPredictedWeighted\n",
    "                totalCorrect += batchCorrect\n",
    "\n",
    "            if np.isnan(np.mean(batchLosses)):\n",
    "                print \"LOSS RETURNED NaN\"\n",
    "                sys.stdout.flush()\n",
    "                return 1\n",
    "\n",
    "            print \"%s Itr: %d - val loss: %.6f, correct: %.6f\" % (time.strftime(\"%H:%M:%S\"),\n",
    "            iteration, float(np.mean(batchLosses)), totalCorrect / totalPredicted)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            if (iteration > 0 and iteration % 5 == 0) or checkSaveFlag(modelSavePath):\n",
    "                modelSaver(sess, modelSavePath, savePrefix, iteration)\n",
    "\n",
    "            #for j in range(10):\n",
    "            for j in range(int(math.floor(trainFeeder.total_samples() / batchSize))):\n",
    "                # print \"attempting to run train batch\"\n",
    "                # sys.stdout.flush()\n",
    "\n",
    "                imageBatch, gtBatch, weightBatch, ssBatch, ssMaskBatch, _ = trainFeeder.next_batch()\n",
    "                sess.run(train_op, feed_dict={tfBatchImages: imageBatch,\n",
    "                                              tfBatchGT: gtBatch,\n",
    "                                              tfBatchWeight: weightBatch,\n",
    "                                              tfBatchSS: ssBatch,\n",
    "                                              tfBatchSSMask: ssMaskBatch,\n",
    "                                              keepProb: 0.7})\n",
    "                # print \"ran one iteration\"\n",
    "\n",
    "            iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cv2.imread(\"../../pytorch-nested-unet/outputs/42/train/species_42_das_20_image_eve.png.json_slice_0001.png\", cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5b9c0af990>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputChannels = 2\n",
    "classType = 'unified_CR'\n",
    "# 0 leaf --> background?\n",
    "indices = [0]\n",
    "savePrefix = \"direction_\" + classType + \"_unified_CR_pretrain\"\n",
    "batchSize = 2\n",
    "learningRate = 1e-5\n",
    "# learningRateActual = 1e-7\n",
    "wd = 1e-5\n",
    "initialIteration = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_model(outputChannels=outputChannels, wd=wd, modelWeightPaths=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ioUtils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeeder = Batch_Feeder(dataset_path=\"../../watershednet/data/for_training/42/\", \n",
    "                           indices=indices,\n",
    "                           subset='train',\n",
    "                           batchSize=batchSize,\n",
    "                           padWidth=None,\n",
    "                           padHeight=None, \n",
    "                           flip=False,\n",
    "                           keepEmpty=False,\n",
    "                           train=True,\n",
    "                           img_shape = (384,384))\n",
    "trainFeeder.set_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeeder._paths[0].angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons = trainFeeder.polygons[trainFeeder._paths[1].img]['polygons']\n",
    "ss = trainFeeder.load_mask(np.zeros((384,384,3)), polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valFeeder = Batch_Feeder(dataset_path=\"../../watershednet/data/for_training/42/\", \n",
    "                           indices=indices,\n",
    "                           subset='val',\n",
    "                           batchSize=batchSize,\n",
    "                           padWidth=None,\n",
    "                           padHeight=None, \n",
    "                           flip=False,\n",
    "                           keepEmpty=False,\n",
    "                           train=True,\n",
    "                           img_shape = (384,384))\n",
    "valFeeder.set_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, outputChannels, learningRate, trainFeeder, valFeeder, modelSavePath=None, savePrefix=None, initialIteration=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import direction_model\n",
    "from ioUtils import *\n",
    "import math\n",
    "import lossFunction\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     tfBatchImages = tf.placeholder(\"float\", shape=[None, 384, 384, 3])\n",
    "#     tfBatchGT = tf.placeholder(\"float\", shape=[None, 384, 384, 2])\n",
    "#     tfBatchSS = tf.placeholder(\"float\", shape=[None, 384, 384])\n",
    "\n",
    "#     with tf.name_scope(\"model_builder\"):\n",
    "#         print (\"attempting to build model\")\n",
    "#         model.build(tfBatchImages, tfBatchSS)\n",
    "#         print (\"built the model\")\n",
    "        \n",
    "#     sys.stdout.flush()\n",
    "#     loss = lossFunction.angularErrorLoss(pred=model.output, gt=tfBatchGT, ss=tfBatchSS, outputChannels=outputChannels)\n",
    "\n",
    "#     angleError = lossFunction.angularErrorTotal(pred=model.output, gt=tfBatchGT, ss=tfBatchSS, outputChannels=outputChannels)\n",
    "#     numPredicted = lossFunction.countTotal(ss=tfBatchSS)\n",
    "#     #numPredictedWeighted = lossFunction.countTotalWeighted(ss=tfBatchSS, weight=tfBatchWeight)\n",
    "#     exceed45 = lossFunction.exceedingAngleThreshold(pred=model.output, gt=tfBatchGT,\n",
    "#                                                     ss=tfBatchSS, threshold=45.0, outputChannels=outputChannels)\n",
    "#     exceed225 = lossFunction.exceedingAngleThreshold(pred=model.output, gt=tfBatchGT,\n",
    "#                                                     ss=tfBatchSS, threshold=22.5, outputChannels=outputChannels)\n",
    "\n",
    "#     train_op = tf.train.AdamOptimizer(learning_rate=learningRate).minimize(loss=loss)\n",
    "\n",
    "#     init = tf.initialize_all_variables()\n",
    "\n",
    "#     sess.run(init)\n",
    "#     iteration = initialIteration\n",
    "    \n",
    "    \n",
    "#     while iteration < 1000:\n",
    "#         batchLosses = []\n",
    "#         totalAngleError = 0\n",
    "#         totalExceed45 = 0\n",
    "#         totalExceed225 = 0\n",
    "#         totalPredicted = 0\n",
    "\n",
    "#         for k in tqdm(range(int(math.floor(valFeeder.total_samples() / batchSize)))):\n",
    "#             imageBatch, gtBatch, ssBatch = valFeeder.next_batch()\n",
    "\n",
    "#             batchLoss, batchAngleError, batchPredicted, batchExceed45, batchExceed225 = sess.run(\n",
    "#                 [loss, angleError, numPredicted, exceed45, exceed225],\n",
    "#                 feed_dict={tfBatchImages: imageBatch,\n",
    "#                            tfBatchGT: gtBatch,\n",
    "#                            tfBatchSS: ssBatch})\n",
    "#             # print \"ran iteration\"\n",
    "#             batchLosses.append(batchLoss)\n",
    "#             totalAngleError += batchAngleError\n",
    "#             totalPredicted += batchPredicted\n",
    "#             totalExceed45 += batchExceed45\n",
    "#             totalExceed225 += batchExceed225\n",
    "\n",
    "#         if np.isnan(np.mean(batchLosses)):\n",
    "#             print (\"LOSS RETURNED NaN\")\n",
    "#             sys.stdout.flush()\n",
    "#             break\n",
    "\n",
    "#         print (\"%s Itr: %d - val loss: %.3f, angle MSE: %.3f, exceed45: %.3f, exceed22.5: %.3f\" % (\n",
    "#             time.strftime(\"%H:%M:%S\"), iteration,\n",
    "#         float(np.mean(batchLosses)), totalAngleError / totalPredicted,\n",
    "#         totalExceed45 / totalPredicted, totalExceed225 / totalPredicted))\n",
    "#         sys.stdout.flush()\n",
    "\n",
    "#         if (iteration > 0 and iteration % 5 == 0) or checkSaveFlag(modelSavePath):\n",
    "#             modelSaver(sess, modelSavePath, savePrefix, iteration)\n",
    "\n",
    "#         for j in range(int(math.floor(trainFeeder.total_samples() / batchSize))):\n",
    "#             # print \"running batch %d\"%(j)\n",
    "#             # sys.stdout.flush()\n",
    "#             imageBatch, gtBatch, ssBatch = trainFeeder.next_batch()\n",
    "#             sess.run(train_op, feed_dict={tfBatchImages: imageBatch,\n",
    "#                                           tfBatchGT: gtBatch,\n",
    "#                                           tfBatchSS: ssBatch})\n",
    "#         iteration += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model=model, outputChannels=outputChannels,\n",
    "                learningRate=learningRate,\n",
    "                trainFeeder=trainFeeder, valFeeder=valFeeder,\n",
    "                modelSavePath=\"./cityscapes/models/direction\", savePrefix=savePrefix,\n",
    "                initialIteration=initialIteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Batch_Feeder:\n",
    "    def __init__(self, dataset_path, indices, subset, batchSize, padWidth=None, padHeight=None, flip=False, keepEmpty=True, train=True, img_shape=(384,384)):\n",
    "        \n",
    "        assert subset in ['train', 'val', 'test'], \"wrong name of subset\"\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "        self._dataset_path = dataset_path\n",
    "        self._indices = indices\n",
    "        self._subset = subset\n",
    "        self._train = train\n",
    "        self._batchSize = batchSize\n",
    "        self._padWidth = padWidth\n",
    "        self._padHeight = padHeight\n",
    "        self._flip = flip\n",
    "        self._keepEmpty = keepEmpty\n",
    "        self.img_shape = img_shape\n",
    "        mask_path = os.path.join(self._dataset_path, 'polygons.json')\n",
    "        with open(mask_path) as f:\n",
    "            self.polygons = json.load(f)\n",
    "        \n",
    "        # TO DO: implement shuffling\n",
    "        # TO DO: support batch wise inference\n",
    "        \n",
    "\n",
    "    def set_paths(self):\n",
    "        self.root = os.path.join(self._dataset_path, self._subset)\n",
    "        print('scanning {}'.format(self.root))\n",
    "        self._paths = []\n",
    "        \n",
    "        imgs = sorted([i for i in os.listdir(self.root) if i.endswith('.png')])\n",
    "        gt_DT = sorted([i for i in os.listdir(self.root) if i.endswith('.npy') and 'DT' in i])\n",
    "        gt_angle = sorted([i for i in os.listdir(self.root) if i.endswith('.npy') and 'angle' in i])\n",
    "\n",
    "#         if self._train:\n",
    "\n",
    "        # TO DO: support batch wise inference\n",
    "\n",
    "        entry = namedtuple(\"gt\", \"index img angle dt\")\n",
    "        for index, (img, angle, dt) in enumerate(zip(imgs, gt_angle, gt_DT)):\n",
    "            self._paths.append(entry(index, img, angle, dt))\n",
    "\n",
    "             \n",
    "\n",
    "            self.shuffle()\n",
    "#         else:\n",
    "#             for id in idList:\n",
    "#                 self._paths.append([id, imageDir + '/' + id + '_leftImg8bit.png',\n",
    "#                                     ssDir + '/' + id + '_unified_ss.mat'])\n",
    "\n",
    "        self._numData = len(self._paths)\n",
    "\n",
    "        if self._numData < self._batchSize:\n",
    "            self._batchSize = self._numData\n",
    "\n",
    "    def shuffle(self):\n",
    "        np.random.shuffle(self._paths)\n",
    "\n",
    "    def next_batch(self):\n",
    "        idBatch = []\n",
    "        \n",
    "        imageBatch = np.zeros((self._batchSize, self.img_shape[0], self.img_shape[1], 3), dtype=np.int32)\n",
    "        gtBatch = np.zeros((self._batchSize,  self.img_shape[0], self.img_shape[1]))\n",
    "        ssBatch = np.zeros((self._batchSize,  self.img_shape[0], self.img_shape[1]))\n",
    "        \n",
    "        tmp = 0\n",
    "        \n",
    "        if self._train:\n",
    "            while(len(idBatch) < self._batchSize):\n",
    "                \n",
    "                current_tuple = self._paths[self._index_in_epoch]\n",
    "                \n",
    "                rgb = self.load_rgb(os.path.join(self.root, current_tuple.img))\n",
    "        \n",
    "                #angle = self.load_npy(os.path.join(self.root, current_tuple.angle))\n",
    "                dt = self.load_npy(os.path.join(self.root, current_tuple.dt))\n",
    "                \n",
    "                polygons = self.polygons[current_tuple.img]['polygons']\n",
    "                mask = self.load_mask(rgb, polygons)\n",
    "\n",
    "\n",
    "                imageBatch[tmp] = rgb\n",
    "                gtBatch[tmp] = dt\n",
    "                ssBatch[tmp] = mask\n",
    "\n",
    "                idBatch.append(current_tuple.index)\n",
    "                \n",
    "                tmp+=1\n",
    "                if tmp==self._batchSize-1:\n",
    "                    tmp=0\n",
    "                self._index_in_epoch += 1\n",
    "                \n",
    "                if self._index_in_epoch == self._numData:\n",
    "                    self._index_in_epoch = 0\n",
    "                    self.shuffle()\n",
    "\n",
    "            if self._flip and np.random.uniform() > 0.5:\n",
    "                for i in range(len(imageBatch)):\n",
    "                    for j in range(3):\n",
    "                        imageBatch[i,:,:,j] = np.fliplr(imageBatch[i,:,:,j])\n",
    "\n",
    "                    weightBatch[i] = np.fliplr(weightBatch[i])\n",
    "                    ssBatch[i] = np.fliplr(ssBatch[i])\n",
    "                    ssMaskBatch[i] = np.fliplr(ssMaskBatch[i])\n",
    "\n",
    "                    for j in range(2):\n",
    "                        gtBatch[i,:,:,j] = np.fliplr(gtBatch[i,:,:,j])\n",
    "\n",
    "                    gtBatch[i,:,:,0] = -1 * gtBatch[i,:,:,0]\n",
    "            return imageBatch, gtBatch, ssBatch\n",
    "        else:\n",
    "            pass\n",
    "            self._index_in_epoch += self._batchSize\n",
    "            return imageBatch, ssBatch\n",
    "        \n",
    "    def total_samples(self):\n",
    "        return self._numData\n",
    "\n",
    "    def image_scaling(self, rgb_in):\n",
    "        if rgb_in.dtype == np.float32:\n",
    "            rgb_in = rgb_in*255\n",
    "        elif rgb_in.dtype == np.uint8:\n",
    "            rgb_in = rgb_in.astype(np.float32)\n",
    "\n",
    "        # VGG16 was trained using opencv which reads images as BGR, but skimage reads images as RGB\n",
    "        rgb_out = np.zeros(rgb_in.shape).astype(np.float32)\n",
    "        rgb_out[:,:,0] = rgb_in[:,:,2] - VGG_MEAN[2]\n",
    "        rgb_out[:,:,1] = rgb_in[:,:,1] - VGG_MEAN[1]\n",
    "        rgb_out[:,:,2] = rgb_in[:,:,0] - VGG_MEAN[0]\n",
    "\n",
    "        return rgb_out\n",
    "\n",
    "    def pad(self, data):\n",
    "        if self._padHeight and self._padWidth:\n",
    "            if data.ndim == 3:\n",
    "                npad = ((0,self._padHeight-data.shape[0]),(0,self._padWidth-data.shape[1]),(0,0))\n",
    "            elif data.ndim == 2:\n",
    "                npad = ((0, self._padHeight - data.shape[0]), (0, self._padWidth - data.shape[1]))\n",
    "            padData = np.pad(data, npad, mode='constant', constant_values=0)\n",
    "\n",
    "        else:\n",
    "            padData = data\n",
    "\n",
    "        return padData\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def load_rgb(path):\n",
    "        return cv2.cvtColor(cv2.imread(path), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_mask(img, polygons):\n",
    "        \"\"\"\n",
    "        Transforms polygons of a single image into a 2D binary numpy array\n",
    "        \n",
    "        :param img: just to get the corresponding shape of the output array\n",
    "        :param polygons: - dict\n",
    "        \n",
    "        :return mask: numpy array with drawn over and touching polygons\n",
    "        \"\"\"\n",
    "        mask = np.zeros([img.shape[0], img.shape[1]], dtype=np.uint8)\n",
    "        for curr_pol in polygons:\n",
    "            cv2.fillPoly(mask, [np.array(curr_pol, 'int32')], 255)\n",
    "        return mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_npy(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            depth = np.load(f)\n",
    "        return depth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((trainFeeder._batchSize, trainFeeder.img_shape[0], trainFeeder.img_shape[1], 3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainFeeder = Batch_Feeder(dataset_path=\"../../watershednet/data/for_training/42/\", \n",
    "                           indices=indices,\n",
    "                           subset='val',\n",
    "                           batchSize=batchSize,\n",
    "                           padWidth=None,\n",
    "                           padHeight=None, \n",
    "                           flip=False,\n",
    "                           keepEmpty=False,\n",
    "                           train=True,\n",
    "                           img_shape = (384,384))\n",
    "trainFeeder.set_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeeder._numData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in tqdm(range(int(np.floor(trainFeeder.total_samples() / batchSize)))):\n",
    "    # print \"running batch %d\"%(j)\n",
    "    # sys.stdout.flush()\n",
    "    imageBatch, gtBatch, ssBatch = trainFeeder.next_batch()\n",
    "    print(imageBatch.shape, gtBatch.shape, ssBatch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageBatch[1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeeder._index_in_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((trainFeeder._batchSize, trainFeeder.img_shape[0], trainFeeder.img_shape[1]))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeeder._paths[40].img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_map =trainFeeder.load_npy(os.path.join(trainFeeder.root, trainFeeder._paths[40].angle))\n",
    "seg_get = trainFeeder.Polygon2Mask2D(angle_map.shape, trainFeeder._paths[40].angle)\n",
    "plt.imshow(seg_get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sio.loadmat('species_38_das_6_image_1.png.json_slice_DT_0013.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = (sio.loadmat(self._paths[self._index_in_epoch][3])['mask']).astype(float)\n",
    "ssMask = ss\n",
    "ss = np.sum(ss[:,:,self._indices], 2)\n",
    "\n",
    "background = np.zeros(ssMask.shape[0:2] + (1,))\n",
    "ssMask = np.concatenate((ssMask[:,:,[1,2,3,4]], background, ssMask[:,:,[0,5,6,7]]), axis=-1)\n",
    "ssMask = np.argmax(ssMask, axis=-1)\n",
    "ssMask = ssMask.astype(float)\n",
    "ssMask = (ssMask - 4) * 32 # centered at 0, with 0 being background, spaced 32 apart for classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
